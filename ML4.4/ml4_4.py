# -*- coding: utf-8 -*-
"""ML4_4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pquMTLsWVqs04lv_EcYqQ5iI-H8BBLWT

##Методические указания
"""

import warnings
warnings.filterwarnings("ignore")

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.datasets import make_classification
X, y = make_classification(n_samples=10000, n_features=500,
                           n_informative=50, n_repeated=0,
                           class_sep=1, random_state=42)
X_train, X_test, y_train, y_test = train_test_split(X, y,
                                                    test_size=0.25,
                                                    random_state=3)

from sklearn.linear_model import LogisticRegression
lr = LogisticRegression().fit(X_train, y_train)

print(f"Training score: {lr.score(X_train, y_train):.4f}")
print(f"Test score: {lr.score(X_test, y_test):.4f}")

from yellowbrick.model_selection import LearningCurve

visualizer = LearningCurve(
    LogisticRegression(), train_sizes=np.linspace(0.5, 1.0, 10)
).fit(X, y).show()

from sklearn.linear_model import RidgeClassifier
lr = RidgeClassifier(alpha=1000000).fit(X_train, y_train)

print(f"Training score: {lr.score(X_train, y_train):.4f}")
print(f"Test score: {lr.score(X_test, y_test):.4f}")

visualizer = LearningCurve(
    RidgeClassifier(alpha=1000000), train_sizes=np.linspace(0.1, 1.0, 10)
).fit(X, y) .show()

from sklearn.linear_model import RidgeClassifier
trains = []
tests = []
for i in np.logspace(2, 6, 50):
  ridge = RidgeClassifier(alpha=i).fit(X_train, y_train)
  trains.append(ridge.score(X_train, y_train))
  tests.append(ridge.score(X_test, y_test))

plt.plot(trains)
plt.plot(tests)

from sklearn.linear_model import RidgeClassifier
lr = RidgeClassifier(alpha=26500).fit(X_train, y_train)

print(f"Training score: {lr.score(X_train, y_train):.4f}")
print(f"Test score: {lr.score(X_test, y_test):.4f}")

from numpy import genfromtxt
dataset = genfromtxt('https://raw.githubusercontent.com/m-mehdi/tutorials/main/boston_housing.csv', delimiter=',')
X = dataset[:,:-1]
y = dataset[:,-1]
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.25, random_state=0)

"""##Задания для самостоятельного выполнения

#### 1. Загрузите первые 400 строк прилагающегося датасета diabetes.csv.
"""

import pandas as pd

file_path = 'diabetes.csv'
data = pd.read_csv(file_path, nrows=400)

"""#### 2. Сделайте количественное описание датасета: число признаков, статистику по признакам"""

feature_count = data.shape[1]
feature_info = data.describe()

feature_count, feature_info

"""####3. Отделите целевую переменную Outcome."""

X = data.drop('Outcome', axis=1)
y = data['Outcome']

X.head(), y.head()

"""####4. Разделите данные на обучающую и валидационную выборки при помощи train_test_split из библиотеки sklearn.model_selection в соотношении 80-20 (для этого укажите параметр test_size=0.2) с перемешиванием, указав значение параметра random_state=42."""

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)

X_train.shape, X_test.shape, y_train.shape, y_test.shape

"""####5. Создайте объект DecisionTreeClassifier(random_state=1). Обучите модель на обучающих (трейновых) данных. Сделайте предсказание на трейновом и валидационном наборе признаков. Выведите значения метрики f1-scoreдля трейнового и валидационного наборов данных. По полученным значениям метрик сделайте предположение о переобученности модели."""

from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import f1_score

dt_classifier = DecisionTreeClassifier(random_state=1)

dt_classifier.fit(X_train, y_train)

y_train_pred = dt_classifier.predict(X_train)
y_test_pred = dt_classifier.predict(X_test)

f1_score_train = f1_score(y_train, y_train_pred)
f1_score_test = f1_score(y_test, y_test_pred)

f1_score_train, f1_score_test

"""Значение f1-score, равное 1.0 для тренировочного набора, указывает на то, что модель идеально предсказывает результаты на обучающих данных. Однако значительное падение f1-score на валидационном наборе до 0.6364 свидетельствует о том, что модель не так хорошо обобщает результаты на новых данных. Это типичный признак переобучения модели: она слишком хорошо адаптировалась к обучающим данным, потеряв при этом способность к обобщению на новые данные.

####6. Произведите кросс-валидацию с использованием функции cross_validate из библиотеки sklearn.model_selection. По полученным данным, постройте график зависимости значений f1-score от набора данных соответствующей итерации. По графику убедитесь в том, что имеет место переобученность модели.
"""

from sklearn.model_selection import cross_validate
import matplotlib.pyplot as plt

cv_results = cross_validate(dt_classifier, X, y, cv=5, scoring='f1', return_train_score=True)

train_scores = cv_results['train_score']
test_scores = cv_results['test_score']

plt.figure(figsize=(10, 5))
plt.plot(train_scores, label='f1-оценка для обучения', marker='o')
plt.plot(test_scores, label='f1-оценка для валидации', marker='o')
plt.title('f1-оценка дерева решений на каждой итерации кросс-валидации')
plt.xlabel('Номер итерации')
plt.ylabel('f1-оценка')
plt.legend()
plt.grid(True)
plt.show()

"""####7. Для борьбы с переобучением регуляризуйте модель DecisionTreeClassifier, уменьшив глубину дерева, указав параметр регуляризации max_depth=3."""

dt_classifier_regularized = DecisionTreeClassifier(random_state=1, max_depth=3)
dt_classifier_regularized.fit(X_train, y_train)

y_train_pred_regularized = dt_classifier_regularized.predict(X_train)
y_test_pred_regularized = dt_classifier_regularized.predict(X_test)

f1_score_train_regularized = f1_score(y_train, y_train_pred_regularized)
f1_score_test_regularized = f1_score(y_test, y_test_pred_regularized)

f1_score_train_regularized, f1_score_test_regularized

"""Сравнение с предыдущими результатами показывает, что разница между f1-оценкой на тренировочной и валидационной выборках значительно сократилась, что указывает на уменьшение переобучения.

####8. Снова проделайте пункт 6 с учётом регуляризации и убелитесь по графику в том, что модель больше не является переобученной.
"""

cv_results_regularized = cross_validate(dt_classifier_regularized, X, y, cv=5, scoring='f1', return_train_score=True)

train_scores_regularized = cv_results_regularized['train_score']
test_scores_regularized = cv_results_regularized['test_score']

plt.figure(figsize=(10, 5))
plt.plot(train_scores_regularized, label='f1-оценка для обучения', marker='o')
plt.plot(test_scores_regularized, label='f1-оценка для валидации', marker='o')
plt.title('f1-оценка дерева решений с регуляризацией (max_depth=3) на каждой итерации кросс-валидации')
plt.xlabel('Номер итерации')
plt.ylabel('f1-оценка')
plt.legend()
plt.grid(True)
plt.show()

"""Из графика видно, что разрыв между f1-оценками на обучающих и валидационных данных значительно сократился по сравнению с первоначальной моделью без регуляризации.

####9. Теперь рассмотрите проблему недообучения модели. Для борьбы с недообучением модели добавьте данные. Для этого загрузите все строки датасета diabetes.csv.
"""

full_data = pd.read_csv(file_path)

full_data.shape

"""####10. Обучите модель DecisionTreeClassifier(random_state=1, max_depth=3) на всех данных и убедитесь в том, что значение метрики f1-score улучшилось."""

X_full = full_data.drop('Outcome', axis=1)
y_full = full_data['Outcome']

dt_classifier_full = DecisionTreeClassifier(random_state=1, max_depth=3)
dt_classifier_full.fit(X_full, y_full)

cv_results_full = cross_validate(dt_classifier_full, X_full, y_full, cv=5, scoring='f1', return_train_score=True)

mean_train_f1_full = cv_results_full['train_score'].mean()
mean_test_f1_full = cv_results_full['test_score'].mean()

mean_train_f1_full, mean_test_f1_full

""" Увеличение объёма данных привело к улучшению f1-оценки на валидационных данных, что говорит о том, что модель стала лучше обобщать."""

train_scores_full = cv_results_full['train_score']
test_scores_full = cv_results_full['test_score']

plt.figure(figsize=(10, 5))
plt.plot(train_scores_full, label='f1-оценка для обучения', marker='o')
plt.plot(test_scores_full, label='f1-оценка для валидации', marker='o')
plt.title('f1-оценка дерева решений на полных данных на каждой итерации кросс-валидации')
plt.xlabel('Номер итерации')
plt.ylabel('f1-оценка')
plt.legend()
plt.grid(True)
plt.show()

"""Из графика видно, что f1-оценки для обучения и валидации более стабильны и близки друг к другу по сравнению с предыдущими моделями на ограниченных данных."""