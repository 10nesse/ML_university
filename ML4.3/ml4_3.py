# -*- coding: utf-8 -*-
"""ML4_3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Nlr26VF-VNq11oxqx1K1616UWT_ywNpt

##Методические указания
"""

import warnings
warnings.filterwarnings("ignore")

import pandas as pd
from sklearn.datasets import load_iris

iris = load_iris()
X=iris.data
y=iris.target

iris_data = pd.DataFrame(iris['data'], columns=iris['feature_names'])
name_map = {0: 'Iris-setosa', 1: 'Iris-versicolor', 2:'Iris-virginica'}
iris_data['class'] = [name_map[k] for k in iris['target']]
iris_data.head(10)

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=5)

from sklearn.metrics import accuracy_score, f1_score
from sklearn.linear_model import LogisticRegression

model = LogisticRegression(solver='liblinear')
model.fit(X_train, y_train) #Обучение трейновой выборке
y_pred = model.predict(X_test) #Предсказание для тестовой выборки
print(accuracy_score(y_test, y_pred))
print(f1_score(y_test, y_pred, average='macro'))

import seaborn as sns
from sklearn.metrics import confusion_matrix

sns.heatmap(confusion_matrix(y_test, y_pred), annot=True)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=0)
model = LogisticRegression()
model.fit(X_train, y_train) #Обучение трейновой выборке
y_pred = model.predict(X_test) #Предсказание для тестовой выборки
print(accuracy_score(y_test, y_pred))
print(f1_score(y_test, y_pred, average='macro'))

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=8)
model = LogisticRegression()
model.fit(X_train, y_train) #Обучение трейновой выборке
y_pred = model.predict(X_test) #Предсказание для тестовой выборки
print(accuracy_score(y_test, y_pred))
print(f1_score(y_test, y_pred, average='macro'))

from sklearn.model_selection import KFold,StratifiedKFold,LeaveOneOut, cross_val_score

kf = KFold(n_splits = 3,shuffle=True, random_state=15)
kf

for i, (train_index, test_index) in enumerate(kf.split(y)):
    print("Fold {}: Длинна train: {}, Длинна test: {}".format(i+1, len(train_index), len(test_index)))
    print('Train: index={}\n Test:  index={}'.format(train_index, test_index))

    X_train, X_test = X[train_index], X[test_index]
    y_train, y_test = y[train_index], y[test_index]

metrics_accuracy = []
metrics_f1 = []
model = LogisticRegression(solver='liblinear')
for i, (train_index, test_index) in enumerate(kf.split(y)):
    X_train, X_test = X[train_index], X[test_index]
    y_train, y_test = y[train_index], y[test_index]
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    metrics_accuracy.append(accuracy_score(y_test, y_pred))
    metrics_f1.append(f1_score(y_test, y_pred, average='macro'))

print('Значения метрики accuracy: {} \nЗначения метрики f1: {}'.format(metrics_accuracy, metrics_f1))

import numpy as np
print("Среднее по кросс-валидации: ", np.array(metrics_f1).mean())

cv_results = cross_val_score(model,                  # модель
                             X,                      # матрица признаков
                             y,                      # вектор цели
                             cv = kf,                # тип разбиения (можно указать просто число фолдов cv = 3)
                             scoring = 'accuracy',   # метрика
                             n_jobs=-1)              # используются все ядра CPU

print("Кросс-валидация: ", cv_results)
print("Среднее по кросс-валидации: ", cv_results.mean())
print("Дисперсия по кросс-валидации: ", cv_results.std())

skf = StratifiedKFold(n_splits=3,shuffle=True, random_state=15)
skf.get_n_splits(X, y)

for i, (train_index, test_index) in enumerate(skf.split(X,y)):
    print(f"Fold {i+1}:")
    print('Train: index={}\n Test:  index={}'.format(train_index, test_index))

    X_train, X_test = X[train_index], X[test_index]
    y_train, y_test = y[train_index], y[test_index]

cv_results = cross_val_score(model,                  # модель
                             X,                      # матрица признаков
                             y,                      # вектор цели
                             cv = skf,           # тип разбиения
                             scoring = 'f1_macro',   # метрика
                             n_jobs=-1)              # используются все ядра CPU

print("Кросс-валидация: ", cv_results)
print("Среднее по кросс-валидации: ", cv_results.mean())

loo = LeaveOneOut()

for i, (train_index, test_index) in enumerate(loo.split(X)):
    print(f"Fold {i+1}:")
    print('Train: index={}\n Test:  index={}'.format(train_index, test_index))

    X_train, X_test = X[train_index], X[test_index]
    y_train, y_test = y[train_index], y[test_index]

cv_results = cross_val_score(model,                  # модель
                             X,                      # матрица признаков
                             y,                      # вектор цели
                             cv = loo,           # тип разбиения
                             scoring = 'f1_macro',   # метрика
                             n_jobs=-1)              # используются все ядра CPU

print("Кросс-валидация: ", cv_results)
print("Среднее по кросс-валидации: ", cv_results.mean())

"""##Задания для самостоятельного выполнения

#### 1. Загрузите датасет ирисы Фишера из библиотеки sklearn.datasets.
"""

from sklearn.datasets import load_iris

iris = load_iris()
X = iris.data
y = iris.target

X, y

"""#### 2. Сделайте hold-out разбиение данных. Для этого разделите данные на обучающую и валидационную выборки и выведите на экран соответствующие индексы разбиения."""

from sklearn.model_selection import train_test_split

X_train, X_validation, y_train, y_validation = train_test_split(X, y, test_size=0.2, random_state=42)

# Получение индексов обучающей и валидационной выборок
train_indexes = X_train.index if hasattr(X_train, 'index') else range(len(X_train))
validation_indexes = X_validation.index if hasattr(X_validation, 'index') else range(len(X_train), len(X_train) + len(X_validation))

train_indexes, validation_indexes

"""####3. Теперь сделайте разбиение перемешанных данных, зафиксировав воспроизводимость выбора данных после перемешивания, указав значение параметра random_state=42 и выведите на экран соответствующие индексы разбиения."""

X_train_shuffled, X_validation_shuffled, y_train_shuffled, y_validation_shuffled = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)

# Поскольку индексы не доступны напрямую (данные являются numpy массивами), используем альтернативный способ определения индексов через mask
# Создадим полный массив индексов
full_indexes = range(len(X))

# Находим обучающие индексы как те, которые не в валидационном наборе, и наоборот
train_mask = np.isin(full_indexes, train_indexes, invert=True)
validation_mask = np.isin(full_indexes, validation_indexes)

# Получаем исходные индексы для перемешанных выборок
train_shuffled_indexes = np.array(full_indexes)[train_mask]
validation_shuffled_indexes = np.array(full_indexes)[validation_mask]

train_shuffled_indexes, validation_shuffled_indexes

"""####4. Обучите модель логистической регрессии на обучающих данных. Выведите значения коэффициентов модели, полученных в результате обучения. Сделайте предсказание на тестовом наборе признаков. Выведите значение метрик accuracy и f1-score."""

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, f1_score

model = LogisticRegression(max_iter=200, solver='liblinear')
model.fit(X_train_shuffled, y_train_shuffled)

coefficients = model.coef_

y_pred = model.predict(X_validation_shuffled)

accuracy = accuracy_score(y_validation_shuffled, y_pred)
f1 = f1_score(y_validation_shuffled, y_pred, average='macro')

print("Коэффициенты модели логистической регрессии:\n")
classes = ["Iris-setosa", "Iris-versicolor", "Iris-virginica"]
for index, class_name in enumerate(classes):
    print(f"{class_name}: {coefficients[index]}")
print("\nМетрики на валидационном наборе данных:")
print(f"Accuracy: {accuracy:.4f}")
print(f"F1-Score (macro): {f1:.4f}")

"""####5. Разделите данные на обучающую и валидационную выборки по новому в соотношении 75-25. Обучите модель на этих данных, выведите значения получившихся коэффициентов модели. Выведите значения метрик и сравните их со значениями из предыдущего пункта. Сделайте вывод о том, влияет ли способ разбиения на результат."""

X_train_new, X_validation_new, y_train_new, y_validation_new = train_test_split(X, y, test_size=0.25, random_state=42)

model_new = LogisticRegression(max_iter=200, solver='liblinear')
model_new.fit(X_train_new, y_train_new)

coefficients_new = model_new.coef_

y_pred_new = model_new.predict(X_validation_new)

accuracy_new = accuracy_score(y_validation_new, y_pred_new)
f1_new = f1_score(y_validation_new, y_pred_new, average='macro')

print("Коэффициенты модели логистической регрессии после нового разбиения данных (75-25):\n")
for index, class_name in enumerate(classes):
    print(f"{class_name}: {coefficients_new[index]}")
print("\nМетрики на новом валидационном наборе данных:")
print(f"Accuracy: {accuracy_new:.4f}")
print(f"F1-Score (macro): {f1_new:.4f}")

"""Изменение соотношения разбиения данных на обучающую и валидационную выборки не оказало заметного влияния на результаты классификации модели логистической регрессии в данном случае.

####6. Теперь сделайте k-блочную перекрёстную проверку модели (кросс-валидацию). Сравните полученные метрики с метриками, которые были при hold-out разбиении.
"""

from sklearn.model_selection import cross_val_score

model_cv = LogisticRegression(max_iter=200, solver='liblinear')

# Выполнение k-блочной перекрёстной проверки для метрики accuracy
cv_accuracy = cross_val_score(model_cv, X, y, cv=5, scoring='accuracy')

# Выполнение k-блочной перекрёстной проверки для метрики f1-score с усреднением по макро
cv_f1 = cross_val_score(model_cv, X, y, cv=5, scoring='f1_macro')

cv_accuracy_mean = np.mean(cv_accuracy)
cv_f1_mean = np.mean(cv_f1)

cv_accuracy_mean, cv_f1_mean

"""При предыдущем hold-out разбиении данных мы получили идеальные значения метрик (Accuracy и F1-Score) равные 1.0. В случае кросс-валидации, значения метрик немного ниже, но всё же очень высоки.

Кросс-валидация предоставляет более обобщенную оценку качества модели, так как данные оцениваются на нескольких разбиениях, а результаты усредняются. Это уменьшает влияние конкретного разбиения данных на оценку модели и предоставляет более надежную оценку её способности к обобщению на новых данных.

####7. Теперь сделайте ту же самую перекрёстную проверку модели, используя библиотечную функцию cross_val_score. Убедитесь, что получится тот же результат.
"""

cv_accuracy_repeat = cross_val_score(model_cv, X, y, cv=5, scoring='accuracy')

cv_f1_repeat = cross_val_score(model_cv, X, y, cv=5, scoring='f1_macro')

cv_accuracy_mean_repeat = np.mean(cv_accuracy_repeat)
cv_f1_mean_repeat = np.mean(cv_f1_repeat)

cv_accuracy_mean_repeat, cv_f1_mean_repeat

"""Это подтверждает надёжность и воспроизводимость результатов кросс-валидации с использованием библиотечной функции. Полученные метрики согласуются с предыдущими значениями, что демонстрирует высокое качество модели и её способность к обобщению на новых данных.

####8. Теперь сделайте k-блочную перекрёстную проверку модели (кросс-валидацию) со стратификацией. Проделайте всё тоже самое, что и в предыдущем пункте.
"""

from sklearn.model_selection import StratifiedKFold

cv_stratified = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

cv_accuracy_stratified = cross_val_score(model_cv, X, y, cv=cv_stratified, scoring='accuracy')

cv_f1_stratified = cross_val_score(model_cv, X, y, cv=cv_stratified, scoring='f1_macro')

cv_accuracy_stratified_mean = np.mean(cv_accuracy_stratified)
cv_f1_stratified_mean = np.mean(cv_f1_stratified)

cv_accuracy_stratified_mean, cv_f1_stratified_mean

"""Значения метрик остались такими же, как и при обычной кросс-валидации без стратификации, что указывает на стабильность модели и её способность к обобщению на новых данных, независимо от метода разбиения.

####9. Теперь сделайте перекрёстную проверку, изпользуя leave-one-out разбиение. Проделайте всё тоже самое, что и в предыдущем пункте.
"""

from sklearn.model_selection import LeaveOneOut

# Создание разбиения leave-one-out
cv_loo = LeaveOneOut()

cv_accuracy_loo = cross_val_score(model_cv, X, y, cv=cv_loo, scoring='accuracy')

cv_f1_loo = cross_val_score(model_cv, X, y, cv=cv_loo, scoring='f1_macro')

cv_accuracy_loo_mean = np.mean(cv_accuracy_loo)
cv_f1_loo_mean = np.mean(cv_f1_loo)

cv_accuracy_loo_mean, cv_f1_loo_mean

"""Значения метрик немного ниже, чем при использовании стратифицированной и нестратифицированной k-блочной перекрёстной проверки (где оба показателя были равны 0.96).

Метод leave-one-out предоставляет один из самых строгих способов кросс-валидации, поскольку модель обучается на всех данных, кроме одного элемента, а затем тестируется на этом единственном элементе. Это процесс повторяется для каждого элемента в наборе данных. Такой подход может быть более чувствителен к выбросам и шуму в данных, что может объяснить незначительное снижение метрик по сравнению с другими методами кросс-валидации. Несмотря на это, полученные результаты всё ещё указывают на высокую эффективность модели. ​
"""