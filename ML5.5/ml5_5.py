# -*- coding: utf-8 -*-
"""ML5_5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GuT0Z6RDhObEDqGalRKN4ZHBhMs5P0D2

##Методические указания
"""

import pandas as pd
import numpy as np
import seaborn as sns

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
# %matplotlib inline

import warnings
warnings.filterwarnings("ignore")

training_set = pd.read_csv('titanic.csv')

training_set.head()

training_set.describe()

training_set.describe(include=['O'])

def custom_hist(training_set, title,  xlabel, ylabel='Количество', bins=None):
    figsize = (20,6)
    plt.figure(figsize=figsize)
    plt.grid(True)
    plt.title(title)
    plt.hist(training_set, training_set.max().astype(int) if bins is None else bins)
    plt.xlabel(xlabel)
    plt.ylabel(ylabel)
    plt.show()

custom_hist(training_set["Age"], 'Распределения пассажиров по возрасту', 'Возраст')

custom_hist(training_set["SibSp"], 'Распределения пассажиров по количеству братьев/сестер или супругов',
  'Число братьев/сестер или супругов')

custom_hist(training_set["Parch"], 'Распределения пассажиров по количеству родителей или детей',
  'Число родителей или детей')

custom_hist(training_set["Fare"], 'Распределения пассажиров по стоимости билета',
  'Стоимость билета', bins=20)

training_set['Age'].plot.hist(bins=30)

sns.countplot(x='SibSp', data=training_set)

training_set['Fare']

training_set['Fare'].hist()

training_set['Fare'].hist(bins=40, figsize=(10,4))

sns.countplot(x='Survived', data=training_set)

sns.countplot(x='Survived', data=training_set, hue='Sex')

sns.countplot(x='Survived', data=training_set, hue='Pclass')

sns.boxplot(x='Pclass', y='Age', data=training_set)

columns_to_look = ['Pclass', 'Sex', 'SibSp', 'Parch', 'Embarked']

for column in columns_to_look:
    pivot = training_set.pivot_table(index=column, values='Survived', aggfunc='mean')

    fig, ax = plt.subplots(figsize=(15,5))
    ax.set_title(f'Доля выживших по признаку {column}', fontdict={'size': 16})
    ax.set_ylabel('Доля выживших', fontdict={'size': 12})
    ax.set_xlabel(column, fontdict={'size': 12})

    for cnt in range(pivot.shape[0]):
        value = pivot.iloc[cnt].values[0]
        ax.text(cnt - .05, value + .005, round(value, 2))

    pivot.plot(kind='bar', rot=0, grid=True, legend=False, ax=ax)
    ax.set_xlabel(f'Значения признака {column}', fontdict={'size': 12})
    plt.show()

training_set.info()

training_set.isnull().sum()

training_set.isnull()

training_set.info()

sns.heatmap(training_set.isnull(), yticklabels=False, cbar=False, cmap='viridis')

sns.heatmap(training_set.isnull(), yticklabels=False, cbar=False, cmap='viridis')

training_set.drop('Cabin', axis=1, inplace=True)

training_set.head()

sns.heatmap(training_set.isnull(), yticklabels=False, cbar=False, cmap='viridis')

training_set.dropna(inplace=True)

from sklearn.preprocessing import OneHotEncoder, LabelEncoder
le = LabelEncoder()
cat_enc_le = le.fit_transform(training_set['Sex'])

training_set['Sex'].unique()

np.unique(cat_enc_le)

le.inverse_transform([0,1])

ohe = OneHotEncoder()
cat_enc_ohe = ohe.fit_transform(training_set[['Embarked']])  # Вызываем метод fit_transform, возвращает разреженную матрицу из библиотеки Scipy

training_set.shape

cat_enc_ohe.shape

pd.get_dummies(training_set['Sex'])

pd.get_dummies(training_set['Sex'], drop_first=True)

sex = pd.get_dummies(training_set['Sex'], drop_first=True)

embark = pd.get_dummies(training_set['Embarked'], drop_first=True)

embark.head()

training_set = pd.concat([training_set, sex, embark], axis=1)

training_set.head()

training_set.drop(['Sex', 'Embarked', 'Name', 'Ticket', 'PassengerId'], axis=1, inplace=True)

training_set.head()

"""##Задания для самостоятельного выполнения


"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

"""#### 1. Постройте по получившемуся набору данных простую модель машинного обучения и оцените ее эффективность."""

X = training_set.drop('Survived', axis=1)
y = training_set['Survived']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

model = LogisticRegression(max_iter=1000)

model.fit(X_train, y_train)

y_pred = model.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
print(f'Accuracy: {accuracy:.2f}')

conf_matrix = confusion_matrix(y_test, y_pred)
print('Confusion Matrix:')
print(conf_matrix)

class_report = classification_report(y_test, y_pred)
print('Classification Report:')
print(class_report)

"""#### 2. Ответьте на следующие вопросы при помощи визуализации и численных данных по исходному набору данных:"""

training_set = pd.read_csv('titanic.csv')

"""####3. Какова доля выживших после крушения пассажиров? Какова доля мужчин и женщин среди выживших?"""

# Доля выживших
survived_counts = training_set['Survived'].value_counts()
survived_counts.plot.pie(autopct='%1.1f%%', startangle=90, colors=['skyblue', 'lightcoral'])
plt.title('Доля выживших пассажиров')
plt.ylabel('')
plt.show()

# Доля мужчин и женщин среди выживших

survived_gender = training_set[training_set['Survived'] == 1]['Sex'].value_counts()
sns.barplot(x=survived_gender.index, y=survived_gender.values, palette='coolwarm')
plt.title('Доля мужчин и женщин среди выживших')
plt.xlabel('Пол')
plt.ylabel('Количество')
plt.show()

"""####4. Сколько пассажиров ехало в каждом классе? Кого было больше в самом многолюдном классе — мужчин или женщин?"""

# Количество пассажиров в каждом классе
class_counts = training_set['Pclass'].value_counts()
sns.barplot(x=class_counts.index, y=class_counts.values, palette='viridis')
plt.title('Количество пассажиров в каждом классе')
plt.xlabel('Класс')
plt.ylabel('Количество')
plt.show()

# Анализ самого многолюдного класса
most_populous_class = training_set['Pclass'].value_counts().idxmax()
most_populous_class_gender = training_set[training_set['Pclass'] == most_populous_class]['Sex'].value_counts()
sns.barplot(x=most_populous_class_gender.index, y=most_populous_class_gender.values, palette='coolwarm')
plt.title(f'Распределение по полу в самом многолюдном классе (Класс {most_populous_class})')
plt.xlabel('Пол')
plt.ylabel('Количество')
plt.show()

"""####5. Все ли признаки несут в себе полезную информацию? Почему? Избавьтесь от ненужных столбцов.

Я решил удалить столбцы Name, Ticket, PassengerId, и Cabin из-за большого количества пропущенных значений и из-за их неинформативности.
"""

training_set.drop(columns=['PassengerId', 'Name', 'Ticket', 'Cabin'], inplace=True)

"""####6. Посчитайте, насколько сильно коррелируют друг с другом цена за билет и возраст пассажиров. Также проверьте наличие этой зависимости визуально (в этом вам поможет построение диаграммы рассеяния)."""

# 1. Посчитать корреляцию между Fare и Age
correlation = training_set[['Fare', 'Age']].corr().iloc[0, 1]
print(f'Корреляция между Fare и Age: {correlation:.2f}')

# 2. Построить диаграмму рассеяния
plt.figure(figsize=(10, 6))
sns.scatterplot(data=training_set, x='Age', y='Fare')
plt.title('Диаграмма рассеяния: Age vs Fare')
plt.xlabel('Age')
plt.ylabel('Fare')
plt.grid(True)
plt.show()

"""####7. Правда ли, что чаще выживали пассажиры с более дорогими билетами? А есть ли зависимость выживаемости от класса?"""

import seaborn as sns
import matplotlib.pyplot as plt

# Проверка зависимости выживаемости от стоимости билета
plt.figure(figsize=(10, 6))
sns.histplot(data=training_set, x='Fare', hue='Survived', element='step', stat='density', common_norm=False, palette='viridis')
plt.title('Выживаемость в зависимости от стоимости билета')
plt.xlabel('Стоимость билета')
plt.ylabel('Плотность')
plt.grid(True)
plt.show()

# Проверка зависимости выживаемости от класса
plt.figure(figsize=(10, 6))
sns.countplot(x='Pclass', hue='Survived', data=training_set, palette='viridis')
plt.title('Выживаемость в зависимости от класса')
plt.xlabel('Класс')
plt.ylabel('Количество')
plt.show()

"""На первом графике видно, что пассажиры с более дорогими билетами имели более высокие шансы на выживание. Это можно заметить по большему числу зеленых столбцов (выживших пассажиров) в диапазоне высоких цен на билеты по сравнению с количеством синего (погибших пассажиров). Таким образом, можно сделать вывод, что более дорогие билеты коррелируют с большей вероятностью выживания.

Пассажиры первого класса имели больше шансов на выживание, так как зеленых столбцов (выживших) больше по сравнению с синими (погибших).
Пассажиры второго класса имеют приблизительно равные шансы на выживание и гибель.
Пассажиры третьего класса значительно больше погибали, чем выживали, что видно по преобладанию синего цвета.

####8. Какова связь между стоимостью билета и портом отправления? Выведите минимальную, среднюю и максимальную сумму, которую заплатили пассажиры за проезд. Проделайте то же самое только для тех пассажиров, которые сели на корабль в Саутгемптоне.
"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Связь между стоимостью билета и портом отправления
plt.figure(figsize=(10, 6))
sns.boxplot(x='Embarked', y='Fare', data=training_set, palette='viridis')
plt.title('Связь между стоимостью билета и портом отправления')
plt.xlabel('Порт отправления')
plt.ylabel('Стоимость билета')
plt.grid(True)
plt.show()

# Минимальная, средняя и максимальная сумма за проезд для всех пассажиров
fare_stats_all = training_set['Fare'].agg(['min', 'mean', 'max'])
print(f"Минимальная сумма за проезд (все пассажиры): {fare_stats_all['min']:.2f}")
print(f"Средняя сумма за проезд (все пассажиры): {fare_stats_all['mean']:.2f}")
print(f"Максимальная сумма за проезд (все пассажиры): {fare_stats_all['max']:.2f}")

# Минимальная, средняя и максимальная сумма за проезд для пассажиров, севших в Саутгемптоне
fare_stats_southampton = training_set[training_set['Embarked'] == 'S']['Fare'].agg(['min', 'mean', 'max'])
print(f"Минимальная сумма за проезд (Саутгемптон): {fare_stats_southampton['min']:.2f}")
print(f"Средняя сумма за проезд (Саутгемптон): {fare_stats_southampton['mean']:.2f}")
print(f"Максимальная сумма за проезд (Саутгемптон): {fare_stats_southampton['max']:.2f}")

"""Пассажиры, отправившиеся из Шербура (C), в среднем заплатили больше за билеты и имеют наиболее значительную вариативность стоимости билетов.
Пассажиры из Саутгемптона (S) и Квинстауна (Q) в среднем заплатили меньше, и стоимость их билетов была более сгруппирована.

####9. Выведите гистограммы, показывающие распределения стоимостей билетов в зависимости от места посадки.
"""

# Гистограммы, показывающие распределения стоимостей билетов в зависимости от места посадки
plt.figure(figsize=(15, 5))

# Саутгемптон (S)
plt.subplot(1, 3, 1)
sns.histplot(training_set[training_set['Embarked'] == 'S']['Fare'], bins=30, kde=True, color='skyblue')
plt.title('Распределение стоимости билетов - Саутгемптон (S)')
plt.xlabel('Стоимость билета')
plt.ylabel('Количество')

# Шербур (C)
plt.subplot(1, 3, 2)
sns.histplot(training_set[training_set['Embarked'] == 'C']['Fare'], bins=30, kde=True, color='lightgreen')
plt.title('Распределение стоимости билетов - Шербур (C)')
plt.xlabel('Стоимость билета')
plt.ylabel('Количество')

# Квинстаун (Q)
plt.subplot(1, 3, 3)
sns.histplot(training_set[training_set['Embarked'] == 'Q']['Fare'], bins=30, kde=True, color='lightcoral')
plt.title('Распределение стоимости билетов - Квинстаун (Q)')
plt.xlabel('Стоимость билета')
plt.ylabel('Количество')

plt.tight_layout()
plt.show()

"""####10. Оцените репрезентативность представленной выборки. Сколько всего было пассажиров Титаника? Сколько из них выжило? Какую долю составляет представленный набор данных от всей генеральной совокупности?"""

# Количество записей в наборе данных
total_passengers = len(training_set)
# Количество выживших в наборе данных
total_survived = training_set['Survived'].sum()

print(f'Всего пассажиров в наборе данных: {total_passengers}')
print(f'Всего выживших в наборе данных: {total_survived}')

# Общее количество пассажиров на Титанике
total_passengers_titanic = 2224
# Общее количество выживших на Титанике
total_survived_titanic = 706

# Доля представленного набора данных
proportion_passengers = total_passengers / total_passengers_titanic
proportion_survived = total_survived / total_survived_titanic

print(f'Доля пассажиров в наборе данных от общей численности пассажиров Титаника: {proportion_passengers:.2%}')
print(f'Доля выживших в наборе данных от общей численности выживших на Титанике: {proportion_survived:.2%}')

"""####11. Разделите выборку на тестовую и обучающую части при помощи train_test_split(). Изобразите на графиках распределение некоторых атрибутов и целевой переменной. Насколько однородно получившееся разбиение?"""

from sklearn.model_selection import train_test_split

X = training_set.drop('Survived', axis=1)
y = training_set['Survived']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

train_set = X_train.copy()
train_set['Survived'] = y_train

test_set = X_test.copy()
test_set['Survived'] = y_test

# Функция для построения гистограмм распределения
def plot_distribution(df, columns, title_prefix):
    plt.figure(figsize=(15, 10))
    for i, column in enumerate(columns):
        plt.subplot(2, 2, i + 1)
        sns.histplot(df[column], kde=True, bins=30, color='skyblue')
        plt.title(f'{title_prefix} {column}')
    plt.tight_layout()
    plt.show()

# Визуализация распределения атрибутов для обучающей выборки
plot_distribution(train_set, ['Age', 'Fare', 'Pclass', 'Survived'], 'Обучающая выборка - ')

# Визуализация распределения атрибутов для тестовой выборки
plot_distribution(test_set, ['Age', 'Fare', 'Pclass', 'Survived'], 'Тестовая выборка - ')

# Сравнение распределений
plt.figure(figsize=(15, 10))
for i, column in enumerate(['Age', 'Fare', 'Pclass', 'Survived']):
    plt.subplot(2, 2, i + 1)
    sns.histplot(train_set[column], kde=True, bins=30, color='skyblue', label='Обучающая выборка', stat='density')
    sns.histplot(test_set[column], kde=True, bins=30, color='lightgreen', label='Тестовая выборка', stat='density')
    plt.title(f'Распределение {column} - Обучающая vs Тестовая выборка')
    plt.legend()
plt.tight_layout()
plt.show()

"""Вывод: распределение классов неравномерное — в обучающей выборке число погибших превышает число выживших.

####12. Сбалансируйте классы в исходном датасете двумя способами:
"""

training_set = pd.read_csv('titanic.csv')

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.impute import SimpleImputer

# Преобразование категориальных признаков в числовые и обработка пропущенных значений
X = pd.get_dummies(training_set.drop(['Survived', 'Name', 'Cabin', 'Ticket', 'PassengerId'], axis=1), drop_first=True)

# Заполнение пропущенных значений медианой
imputer = SimpleImputer(strategy='median')
X = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)

y = training_set['Survived']

# Разделение данных на тестовую и обучающую выборки
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Количество объектов в каждом классе
class_counts = y_train.value_counts()
min_class = class_counts.idxmin()
maj_class = class_counts.idxmax()

# Удаление лишних объектов мажоритарного класса
train_data = X_train.copy()
train_data['Survived'] = y_train

maj_class_indices = train_data[train_data['Survived'] == maj_class].index
random_indices = np.random.choice(maj_class_indices, len(maj_class_indices) - class_counts[min_class], replace=False)
balanced_train_data_undersample = train_data.drop(index=random_indices)

X_train_undersample = balanced_train_data_undersample.drop('Survived', axis=1)
y_train_undersample = balanced_train_data_undersample['Survived']

# Обучение модели на сбалансированном датасете (undersampling)
model_undersample = LogisticRegression(max_iter=1000)
model_undersample.fit(X_train_undersample, y_train_undersample)

# Предсказание и оценка эффективности
y_pred_undersample = model_undersample.predict(X_test)
print('Оценка модели на сбалансированном датасете (undersampling):')
print(f'Accuracy: {accuracy_score(y_test, y_pred_undersample):.2f}')
print('Confusion Matrix:')
print(confusion_matrix(y_test, y_pred_undersample))
print('Classification Report:')
print(classification_report(y_test, y_pred_undersample))

# Дублирование объектов миноритарного класса
min_class_indices = train_data[train_data['Survived'] == min_class].index
duplicate_indices = np.random.choice(min_class_indices, class_counts[maj_class] - class_counts[min_class], replace=True)
balanced_train_data_oversample = pd.concat([train_data, train_data.loc[duplicate_indices]])

X_train_oversample = balanced_train_data_oversample.drop('Survived', axis=1)
y_train_oversample = balanced_train_data_oversample['Survived']

# Обучение модели на сбалансированном датасете (oversampling)
model_oversample = LogisticRegression(max_iter=1000)
model_oversample.fit(X_train_oversample, y_train_oversample)

# Предсказание и оценка эффективности
y_pred_oversample = model_oversample.predict(X_test)
print('Оценка модели на сбалансированном датасете (oversampling):')
print(f'Accuracy: {accuracy_score(y_test, y_pred_oversample):.2f}')
print('Confusion Matrix:')
print(confusion_matrix(y_test, y_pred_oversample))
print('Classification Report:')
print(classification_report(y_test, y_pred_oversample))

"""####16. Постройте корреляционную матрицу признаков после преобразования данных. Сделайте вывод о наличии либо отсутствии мультиколлинеарности признаков."""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.impute import SimpleImputer

# Преобразование категориальных признаков в числовые и обработка пропущенных значений
X = pd.get_dummies(training_set.drop(['Survived', 'Name', 'Cabin', 'Ticket', 'PassengerId'], axis=1), drop_first=True)

# Заполнение пропущенных значений медианой
imputer = SimpleImputer(strategy='median')
X = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)

# Построение корреляционной матрицы
corr_matrix = X.corr()

# Визуализация корреляционной матрицы
plt.figure(figsize=(12, 8))
sns.heatmap(corr_matrix, annot=True, fmt=".2f", cmap='coolwarm', linewidths=0.5)
plt.title('Корреляционная матрица признаков')
plt.show()

# Анализ мультиколлинеарности
print(corr_matrix)

"""Между признаками Pclass и Fare (-0.55). Это означает, что более высокий класс (более низкое значение Pclass) обычно ассоциируется с более высокой стоимостью билета.

Между признаками SibSp и Parch (0.41). Это означает, что наличие братьев/сестер/супругов коррелирует с наличием родителей/детей на борту. Это логично, так как семьи, путешествующие вместе, обычно имеют как братьев/сестер, так и родителей/детей.

Признаки Embarked_Q и Embarked_S имеют отрицательную корреляцию (-0.50), что ожидаемо, так как они представляют собой категориальные переменные, закодированные методом One-Hot Encoding, и взаимоисключают друг друга.

Большинство других признаков имеют слабую корреляцию между собой (менее 0.3 по абсолютному значению), что указывает на отсутствие сильной мультиколлинеарности среди этих признаков.

####17. Проведите группировку данных по значению возраста. Введите новый признак "возрастная категория", значениями которой будут "ребенок", "взрослый", "старик". Проведите анализ эффективности данного признака.
"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.impute import SimpleImputer

# Функция для создания возрастной категории
def age_category(age):
    if age < 18:
        return 'ребенок'
    elif age < 60:
        return 'взрослый'
    else:
        return 'старик'

# Создание нового признака "возрастная категория"
training_set['AgeCategory'] = training_set['Age'].apply(age_category)

# Анализ распределения нового признака
plt.figure(figsize=(10, 6))
sns.countplot(x='AgeCategory', hue='Survived', data=training_set)
plt.title('Распределение возрастных категорий среди выживших и погибших')
plt.xlabel('Возрастная категория')
plt.ylabel('Количество')
plt.show()

# Преобразование категориального признака AgeCategory в числовой формат
training_set = pd.get_dummies(training_set, columns=['AgeCategory'], drop_first=True)

# Подготовка данных с новым признаком
X = pd.get_dummies(training_set.drop(['Survived', 'Name', 'Cabin', 'Ticket', 'PassengerId'], axis=1), drop_first=True)

# Заполнение пропущенных значений медианой
imputer = SimpleImputer(strategy='median')
X = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)

y = training_set['Survived']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

model = LogisticRegression(max_iter=1000)
model.fit(X_train, y_train)

y_pred = model.predict(X_test)
print('Оценка модели на датасете с новым признаком:')
print(f'Accuracy: {accuracy_score(y_test, y_pred):.2f}')
print('Confusion Matrix:')
print(confusion_matrix(y_test, y_pred))
print('Classification Report:')
print(classification_report(y_test, y_pred))