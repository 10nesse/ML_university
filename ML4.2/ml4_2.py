# -*- coding: utf-8 -*-
"""ML4_2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IgWFnmmwSaJHGJVy8FZDm2_OxtB5BWiO

##Методические указания
"""

import warnings
warnings.filterwarnings("ignore")

from sklearn.datasets import make_classification

X, y = make_classification(n_samples=1000, n_classes=2, random_state=1)

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=2)

from sklearn.linear_model import LogisticRegression

model = LogisticRegression().fit(X_train, y_train)

y_pred_proba = model.predict_proba(X_test)

from sklearn.metrics import roc_curve

fpr, tpr, _ = roc_curve(y_test, y_pred_proba[:, 1])

import matplotlib.pyplot as plt

plt.plot([0, 1], [0, 1], linestyle='--')
plt.plot(fpr, tpr, marker='.')
plt.show()

from sklearn.metrics import roc_auc_score

roc_auc_score(y_test, y_pred_proba[:, 1])

from sklearn.metrics import precision_recall_curve

precision, recall, _ = precision_recall_curve(y_test, y_pred_proba[:, 1])

no_skill = len(y[y==1]) / len(y)
plt.plot([0, 1], [no_skill, no_skill], linestyle='--')

plt.plot(recall, precision, marker='.')
plt.show()

from sklearn.metrics import auc

auc(recall, precision)

from sklearn.metrics import classification_report

y_test_pred = model.predict(X_test)
print(classification_report(y_test, y_test_pred))

from sklearn.neighbors import KNeighborsClassifier

model2 = KNeighborsClassifier(n_neighbors=250).fit(X_train, y_train)
y_pred2_proba = model2.predict_proba(X_test)
fpr, tpr, _ = roc_curve(y_test, y_pred2_proba[:, 1])

plt.plot([0, 1], [0, 1], linestyle='--')
plt.plot(fpr, tpr, marker='.')
plt.show()

roc_auc_score(y_test, y_pred2_proba[:, 1])

X, y = make_classification(n_samples=1000, n_classes=2, weights=[0.99, 0.01], random_state=1)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=4)

print('Датасет: Class0=%d, Class1=%d' % (len(y[y==0]), len(y[y==1])))
print('Обучающая: Class0=%d, Class1=%d' % (len(y_train[y_train==0]), len(y_train[y_train==1])))
print('Тестовая: Class0=%d, Class1=%d' % (len(y_test[y_test==0]), len(y_test[y_test==1])))

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, stratify=y)

model = LogisticRegression().fit(X_train, y_train)
y_pred_proba = model.predict_proba(X_test)

y_test_pred = model.predict(X_test)
print(classification_report(y_test, y_test_pred))

fpr, tpr, _ = roc_curve(y_test, y_pred_proba[:, 1])

plt.plot([0, 1], [0, 1], linestyle='--')
plt.plot(fpr, tpr, marker='.')
plt.show()

precision, recall, _ = precision_recall_curve(y_test, y_pred_proba[:, 1])
no_skill = len(y[y==1]) / len(y)
plt.plot([0, 1], [no_skill, no_skill], linestyle='--')
plt.plot(recall, precision, marker='.')
plt.show()

X, y = make_classification(n_samples=10000, n_classes=2, weights=[0.99, 0.01], random_state=1)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, stratify=y)

model = LogisticRegression().fit(X_train, y_train)
y_pred_proba = model.predict_proba(X_test)

p, r, pr_thresholds = precision_recall_curve(y_test, y_pred_proba[:, 1])
no_skill = len(y[y==1]) / len(y)
plt.plot([0, 1], [no_skill, no_skill], linestyle='--')
plt.plot(r, p, marker='.')
plt.show()

from numpy import argmax

f1 = (2 * p * r) / (p + r)
ix = argmax(f1)
pr_thresholds[ix]

print('Порог=%f, F-Score=%.3f' % (pr_thresholds[ix], f1[ix]))

plt.plot([0, 1], [no_skill, no_skill], linestyle='--')
plt.plot(r, p, marker='.')
plt.scatter(r[ix], p[ix], marker='o', color='black')
plt.show()

y_pred = (y_pred_proba[:, 1] > pr_thresholds[ix]).astype('int')

print(classification_report(y_test, y_pred))

y_pred = model.predict(X_test)
print(classification_report(y_test, y_pred))

"""##Задания для самостоятельного выполнения

#### 1. Повторите анализ из лабораторной работы, но с двумерными датасетами. Изобразите графически, как изменение порога влияет на расположение границы принятия решений.
"""

# Создаем двумерный датасет
X, y = make_classification(n_samples=100, n_features=2, n_informative=2, n_redundant=0, n_classes=2, n_clusters_per_class=1, random_state=19)

X_train, y_train = X, y

model = LogisticRegression().fit(X_train, y_train)

plt.figure(figsize=(10, 6))

# Визуализируем точки датасета
plt.scatter(X[:, 0], X[:, 1], c=y, cmap='coolwarm', edgecolors='k', label='Данные')

# Визуализируем границу принятия решений (разделяющую поверхность)
# Для этого создадим сетку точек и вычислим предсказания модели для каждой точки сетки
xx, yy = np.meshgrid(np.linspace(-3, 3, 100), np.linspace(-3, 3, 100))
Z = model.predict(np.c_[xx.ravel(), yy.ravel()])
Z = Z.reshape(xx.shape)

# Визуализируем границу принятия решений как контурный график
plt.contourf(xx, yy, Z, cmap='coolwarm', alpha=0.5, levels=[0, 0.5, 1])

plt.xlabel('Признак 1')
plt.ylabel('Признак 2')
plt.title('Граница принятия решений с порогом по умолчанию')

plt.legend()
plt.colorbar(label='Класс')
plt.grid(True)
plt.show()

"""#### 2. Повторите анализ на реальном датасете для бинарной классификации. Проинтерпретируйте результат, сделайте вывод."""

from sklearn.datasets import load_breast_cancer

data = load_breast_cancer()
X = data.data
y = data.target

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=19)

model = LogisticRegression(max_iter=10000)
model.fit(X_train, y_train)

# Получение вероятностей классов на тестовой выборке
y_pred_proba = model.predict_proba(X_test)[:, 1]

# Построение кривой ROC
fpr, tpr, thresholds_roc = roc_curve(y_test, y_pred_proba)
roc_auc = roc_auc_score(y_test, y_pred_proba)

plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='blue', lw=2, label='ROC-кривая (площадь = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='red', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('Ложно положительная оценка')
plt.ylabel('Истинно положительная оценка')
plt.title('ROC-кривая')
plt.legend(loc='lower right')
plt.show()

# Построение кривой Precision-Recall
precision, recall, thresholds_pr = precision_recall_curve(y_test, y_pred_proba)
pr_auc = auc(recall, precision)

plt.figure(figsize=(8, 6))
plt.plot(recall, precision, color='green', lw=2, label='PR-кривая (площадь = %0.2f)' % pr_auc)
plt.xlabel('Полнота')
plt.ylabel('Точность')
plt.title('PR-кривая')
plt.legend(loc='lower left')
plt.show()

y_pred = model.predict(X_test)
print(classification_report(y_test, y_pred))

"""####3. В задании по оптимизации порога используйте ROC и среднее геометрическое между TPR и FPR как критерий оптимизации."""

data = load_breast_cancer()
X = data.data
y = data.target

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=19)

model = LogisticRegression(max_iter=10000)
model.fit(X_train, y_train)

# Получение вероятностей классов на тестовой выборке
y_pred_proba = model.predict_proba(X_test)[:, 1]

# Построение кривой ROC
fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)

# Вычисление значения среднего геометрического между TPR и FPR для каждого порога
geometric_mean = np.sqrt(tpr * (1 - fpr))

# Находим порог, соответствующий максимальному значению среднего геометрического
best_threshold_index = np.argmax(geometric_mean)
best_threshold = thresholds[best_threshold_index]

# Оценка модели с использованием оптимального порога
y_pred_optimized = (y_pred_proba >= best_threshold).astype(int)

print("Отчет о классификации с оптимальным порогом:")
print(classification_report(y_test, y_pred_optimized))

print("Оптимальный порог:", best_threshold)

# Построение ROC-кривой с оптимальным порогом
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='blue', lw=2, label='ROC-кривая')
plt.plot(fpr[best_threshold_index], tpr[best_threshold_index], marker='o', markersize=8, color='red', label=f'Оптимальный порог: {best_threshold:.2f}')
plt.xlabel('Ложно положительная оценка')
plt.ylabel('Истинно положительная оценка')
plt.title('Характеристика операций приемки (ROC)')
plt.legend(loc='lower right')
plt.show()

"""####4. При оптимизации порога по PR-кривой используйте другую F-метрику - сначала с преимуществом precision, а затем - с превалированием recall. Изобразите получившиеся пороги на графике. Проанализируйте метрики получившихся моделей."""

data = load_breast_cancer()
X = data.data
y = data.target

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=19)

model = LogisticRegression(max_iter=10000)
model.fit(X_train, y_train)

y_pred_proba = model.predict_proba(X_test)[:, 1]

# Построение кривой PR
precision, recall, thresholds = precision_recall_curve(y_test, y_pred_proba)

# Вычисление F-метрики с преимуществом precision для каждого порога
f1_precision = 2 * (precision * recall) / (precision + recall)

# Вычисление F-метрики с преимуществом recall для каждого порога
f1_recall = 2 * (precision * recall) / (precision + recall)

# Находим порог, соответствующий максимальным значениям F-метрик
best_threshold_precision = thresholds[np.argmax(f1_precision)]
best_threshold_recall = thresholds[np.argmax(f1_recall)]

# Оценка модели с использованием оптимальных порогов
y_pred_optimized_precision = (y_pred_proba >= best_threshold_precision).astype(int)
y_pred_optimized_recall = (y_pred_proba >= best_threshold_recall).astype(int)

print("Отчет о классификации с оптимизированным порогом (точность):")
print(classification_report(y_test, y_pred_optimized_precision))

print("Отчет о классификации с оптимизированным порогом (полнота):")
print(classification_report(y_test, y_pred_optimized_recall))

print("Оптимальный порог (точность):", best_threshold_precision)
print("Оптимальный порог (полнота):", best_threshold_recall)


plt.figure(figsize=(8, 6))
plt.plot(recall, precision, color='blue', lw=2, label='Кривая PR')
plt.plot(recall[np.argmax(f1_precision)], precision[np.argmax(f1_precision)], marker='o', markersize=8, color='red', label=f'Оптимальный порог (Precision): {best_threshold_precision:.2f}')
plt.plot(recall[np.argmax(f1_recall)], precision[np.argmax(f1_recall)], marker='o', markersize=8, color='green', label=f'Оптимальный порог (Recall): {best_threshold_recall:.2f}')
plt.xlabel('Полнота')
plt.ylabel('Точность')
plt.title('Кривая Precision-Recall (PR)')
plt.legend(loc='lower left')
plt.show()

"""####5. Постройте классификационные кривые для задачи множественной классификации. Проинтерпретируйте результат."""

# Генерация множественного датасета для классификации
X, y = make_classification(n_samples=1000, n_classes=3, n_features=20, n_clusters_per_class=1, random_state=19)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=19)

model = LogisticRegression(max_iter=1000)
model.fit(X_train, y_train)

y_pred_proba = model.predict_proba(X_test)

plt.figure(figsize=(8, 6))
for i in range(len(model.classes_)):
    fpr, tpr, _ = roc_curve((y_test == i).astype(int), y_pred_proba[:, i])
    roc_auc = auc(fpr, tpr)
    plt.plot(fpr, tpr, label=f'Класс {i} (AUC = {roc_auc:.2f})')
plt.xlabel('Ложно положительный уровень')
plt.ylabel('Истинно положительный уровень')
plt.title('ROC-кривые для многоклассовой классификации')
plt.legend()
plt.grid(True)
plt.show()

"""####6. Используйте для построения кривых библиотеку yellowbrick."""

from yellowbrick.classifier import ROCAUC

X, y = make_classification(n_samples=1000, n_classes=2, n_features=20, random_state=42)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)

model = LogisticRegression(max_iter=1000)
model.fit(X_train, y_train)

# Построение ROC-кривой
visualizer = ROCAUC(model, classes=model.classes_)
visualizer.fit(X_train, y_train)  # Обучение классификатора
visualizer.score(X_test, y_test)  # Оценка тестовых данных
visualizer.show()