# -*- coding: utf-8 -*-
"""ML4_1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1W1JzBnXmeKfqa16viwhdzKhtZTza6LUO

##Методические указания
"""

import warnings
warnings.filterwarnings("ignore")

import pandas as pd

data = pd.read_csv('heart.csv')

y = data["output"]
x = data.drop("output", axis=1)

from sklearn.linear_model import LogisticRegression

logistic = LogisticRegression().fit(x, y)
logistic.score(x, y)

x_train, y_train = x[:200], y[:200]

x_train.shape, y_train.shape

x_test, y_test = x[200:], y[200:]
x_test.shape, y_test.shape

logistic_test = LogisticRegression().fit(x_train, y_train)
logistic_test.score(x_train, y_train), logistic_test.score(x_test, y_test)

N = int(x.shape[0] * 0.8)

x_train, y_train, x_test, y_test = x[:N], y[:N], x[N:], y[N:]
x_train.shape, y_train.shape, x_test.shape, y_test.shape

logistic_test = LogisticRegression().fit(x_train, y_train)
logistic_test.score(x_train, y_train), logistic_test.score(x_test, y_test)

data.tail()

import numpy as np

mask = np.array([True] * N + [False] * (y.shape[0] - N))

from numpy.random import shuffle

shuffle(mask)
mask

x_train = x[mask]
x_train.shape

x_train, y_train, x_test, y_test = x[mask], y[mask], x[~mask], y[~mask]
x_train.shape, y_train.shape, x_test.shape, y_test.shape

logistic_test = LogisticRegression().fit(x_train, y_train)
logistic_test.score(x_train, y_train), logistic_test.score(x_test, y_test)

from sklearn.model_selection import train_test_split

x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.8)
x_train.shape, y_train.shape, x_test.shape, y_test.shape

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report

y_test_pred = logistic_test.predict(x_test)
y_train_pred = logistic_test.predict(x_train)

confusion_matrix(y_train, y_train_pred)

confusion_matrix(y_test, y_test_pred)

print(classification_report(y_test, y_test_pred))

precision_score(y_test, y_test_pred)

metrics = pd.DataFrame({
    "Train": [
        accuracy_score(y_train, y_train_pred),
        precision_score(y_train, y_train_pred),
        recall_score(y_train, y_train_pred),
        f1_score(y_train, y_train_pred),
    ],
    "Test": [
        accuracy_score(y_test, y_test_pred),
        precision_score(y_test, y_test_pred),
        recall_score(y_test, y_test_pred),
        f1_score(y_test, y_test_pred),
    ],
}, index = ["Accuracy", "Precision", "Recall", "F1"])

metrics

"""##Задания для самостоятельного выполнения

#### 1. Повторите анализ для других видов моделей. Используйте 5-10 разных классов моделей. Подсчитывайте только метрики на тестовой выборке.
"""

from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.neural_network import MLPClassifier


X = data.drop('output', axis=1)
y = data['output']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=19)

classifiers = {
    'Logistic Regression': LogisticRegression(),
    'Decision Tree': DecisionTreeClassifier(),
    'Random Forest': RandomForestClassifier(),
    'SVM': SVC(),
    'K Nearest Neighbors': KNeighborsClassifier(),
    'Naive Bayes': GaussianNB(),
    'Neural Network': MLPClassifier()
}

# Обучение и оценка эффективности каждой модели
results = {}
for name, clf in classifiers.items():
    clf.fit(X_train, y_train)
    y_pred = clf.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    results[name] = {'Accuracy': accuracy, 'Precision': precision, 'Recall': recall, 'F1-score': f1}

results_df = pd.DataFrame(results)
print(results_df)

"""Модели Decision Tree, Random Forest и Neural Network показывают сравнимые результаты по точности (Accuracy), прецизии (Precision) и F1-мере (F1-score). Они имеют промежуточные значения между другими моделями.

На основе метрик качества, модели Logistic Regression, Decision Tree, Random Forest и Neural Network можно рассматривать как наиболее перспективные для данной задачи классификации

#### 2. Повторите анализ для другого датасета по вашему выбору. Используйте несколько моделей для сравнения. Используйте датасет для множественной классификации.
"""

from sklearn.datasets import load_wine

wine = load_wine()
X = wine.data
y = wine.target

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=19)

classifiers = {
    'Logistic Regression': LogisticRegression(),
    'Decision Tree': DecisionTreeClassifier(),
    'Random Forest': RandomForestClassifier(),
    'SVM': SVC(),
    'K Nearest Neighbors': KNeighborsClassifier(),
    'Naive Bayes': GaussianNB(),
    'Neural Network': MLPClassifier()
}

results = {}
for name, clf in classifiers.items():
    clf.fit(X_train, y_train)
    y_pred = clf.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred, average='weighted')
    recall = recall_score(y_test, y_pred, average='weighted')
    f1 = f1_score(y_test, y_pred, average='weighted')
    results[name] = {'Accuracy': accuracy, 'Precision': precision, 'Recall': recall, 'F1-score': f1}

results_df = pd.DataFrame(results)
print(results_df)

"""Снова модель Random Forest демонстрирует высокие показатели точности (accuracy) и precision (точность), а также F1-score. Ее accuracy составляет 94.4%, что делает ее лучшим выбором среди рассмотренных моделей.

Модель Logistic Regression также показывает высокие результаты, с точностью, recall и F1-score близкими к 92%. Она является вторым лучшим выбором после модели Random Forest.

Итак, на основании метрик качества, модель Random Forest снова является наилучшим выбором для данной задачи классификации

####3. Повторите анализ для датасета, предназначенного для решения задачи регрессии. Используйте все метрики качества регрессии, изученные на лекции. Постройте 5 - 10 разных моделей регрессии.
"""

from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.svm import SVR
from sklearn.neighbors import KNeighborsRegressor
from sklearn.linear_model import Lasso, Ridge
from sklearn.preprocessing import StandardScaler
from sklearn.datasets import fetch_california_housing

california_housing = fetch_california_housing()
X = california_housing.data
y = california_housing.target

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=19)

# Стандартизация признаков
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

regressors = {
    'Linear Regression': LinearRegression(),
    'Decision Tree': DecisionTreeRegressor(),
    'Random Forest': RandomForestRegressor(),
    'SVR': SVR(),
    'K Neighbors': KNeighborsRegressor(),
    'Lasso': Lasso(),
    'Ridge': Ridge()
}

# Обучение и оценка эффективности каждой модели
results = {}
for name, reg in regressors.items():
    reg.fit(X_train_scaled, y_train)
    y_pred = reg.predict(X_test_scaled)
    mse = mean_squared_error(y_test, y_pred)
    mae = mean_absolute_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)
    results[name] = {'Mean Squared Error': mse, 'Mean Absolute Error': mae, 'R^2 Score': r2}

results_df = pd.DataFrame(results)
print(results_df)

"""Модель Random Forest демонстрирует самые низкие значения среднеквадратичной ошибки (Mean Squared Error) и средней абсолютной ошибки (Mean Absolute Error), а также наивысший коэффициент детерминации (R^2 Score). Это говорит о том, что модель Random Forest лучше всего приближает зависимость между признаками и целевой переменной в данном наборе данных.

Модель SVR (Support Vector Regression) также показывает неплохие результаты, хотя немного уступает по всем метрикам модели Random Forest.

Итак, на основе метрик качества, модель Random Forest является лучшим выбором для данной задачи регрессии
"""